{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Add the parent directory of the module to sys.path\n",
    "sys.path.append(os.path.abspath(r\"E:\\EmailTool-V2\\Barzaan\\email_creator_app\"))\n",
    "from database_training.database_process_mutifile import process_files_and_save_output\n",
    "from database_training.merger_for_pckl import update_pkl_with_csv\n",
    "import pandas as pd\n",
    "from database_training.update_db_manually import update_pickle\n",
    "from email_creation.create_emails import email_creator_app\n",
    "from database_training.database_process_single_file import process_single_file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base directory: e:\\EmailTool-V2\\Barzaan\\email_creator_app\n",
      "Base directory: e:\\EmailTool-V2\\Barzaan\\email_creator_app/files/\n",
      "old_db_pickle_file_path directory: e:\\EmailTool-V2\\Barzaan\\email_creator_app/files/main_database//old_db.pkl\n",
      "e:\\EmailTool-V2\\Barzaan\\email_creator_app\\files\\main_database\n"
     ]
    }
   ],
   "source": [
    "import pickle, os\n",
    "# Get the full path of the script\n",
    "script_path = os.path.abspath('test-notebook.ipynb')\n",
    "# Get the directory containing the script\n",
    "user_path = os.path.dirname(script_path)\n",
    "print(\"Base directory:\", user_path)\n",
    "base_path = user_path+\"/files/\" \n",
    "print(\"Base directory:\", base_path)\n",
    "Source_file_path,Output_files_path = base_path+'database_source_files' ,base_path+'database_output_files'\n",
    "Output_files_path = base_path+'database_output_files'\n",
    "new_db_pickle_file_path, old_db_pickle_file_path = base_path+'main_database//'+'new_db.pkl', base_path+'main_database//'+'old_db.pkl'\n",
    "print(\"old_db_pickle_file_path directory:\", old_db_pickle_file_path)\n",
    "# Read the pickle file\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "file_path = Path(new_db_pickle_file_path)\n",
    "folder_path = file_path.parent\n",
    "print(folder_path) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New 50778\n",
      "Old 1047832\n"
     ]
    }
   ],
   "source": [
    "\n",
    " \n",
    "with open(new_db_pickle_file_path, \"rb\") as file:\n",
    "    new_data_dict = pickle.load(file)  # Load as a dictionary\n",
    "# Print or use the dictionary\n",
    "print(\"New\", len(new_data_dict))\n",
    "# Read the pickle file\n",
    "with open(old_db_pickle_file_path, \"rb\") as file:\n",
    "    data_dict = pickle.load(file)  # Load as a dictionary\n",
    "# Print or use the dictionary\n",
    "print(\"Old\", len(data_dict))\n",
    "# New 48356 2apriil 11.30pm  Old 1045298\n",
    "# New 48975 3 aprl 3.45pm Old 1045929\n",
    "# New 48975 Old 1045929   4 april 9pm New 50741 Old 1047795 \n",
    "# New 50778\n",
    "# Old 1047832"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keys with value 'unknown':\n",
      "New 49004\n"
     ]
    }
   ],
   "source": [
    "# Check if data is a dictionary\n",
    "if isinstance(new_data_dict, dict):\n",
    "    # Find keys with value \"unknown\"\n",
    "    keys_to_remove = [key for key, value in new_data_dict.items() if value == \"Unknown Pattern\"]\n",
    "    # Remove them from the dictionary\n",
    "    for key in keys_to_remove:\n",
    "        del new_data_dict[key]\n",
    "print(\"New\", len(new_data_dict))\n",
    "\n",
    "# # Save the modified data back to a pickle file (optional)\n",
    "# with open(new_db_pickle_file_path, \"wb\") as f:\n",
    "#     pickle.dump(new_data_dict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FirstInitialLastName@1sourcepartners.com FirstInitialLastName@1sourcepartners.com\n"
     ]
    }
   ],
   "source": [
    "k ='10th SFG'\n",
    "k ='1 source medicine'\n",
    "print (new_data_dict[str.lower(k)], data_dict[str.lower(k)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10th sfg : LastName@soc.mil\n",
      "magellan of nevada : FirstInitialLastName@magellanhealth.com\n",
      "magellan pipe line : FirstName.LastName@7n.com\n",
      "maggie shops for you : FirstInitialLastName@hu-friedy.com\n",
      "maggie speaks : FirstName.LastName@7n.com\n",
      "10th sfg : LastName@soc.mil\n",
      "magellan of nevada : FirstInitialLastName@magellanhealth.com\n",
      "magellan pipe line : FirstName.LastName@7n.com\n",
      "maggie shops for you : FirstInitialLastName@hu-friedy.com\n",
      "maggie speaks : FirstName.LastName@7n.com\n",
      "49152\n"
     ]
    }
   ],
   "source": [
    "# Print the first 5 key-value pairs from the dictionary\n",
    "for i, (key, value) in enumerate(new_data_dict.items()):\n",
    "    if i == 5:\n",
    "        break\n",
    "    print(key, \":\", value)\n",
    "\n",
    "\n",
    "\n",
    "# Convert list values to normal strings\n",
    "normalized_dict = {key: value[0] if isinstance(value, list) and len(value) == 1 else value for key, value in new_data_dict.items()}\n",
    "\n",
    "# Print normalized dictionary\n",
    "# Print the first 5 key-value pairs from the dictionary\n",
    "for i, (key, value) in enumerate(normalized_dict.items()):\n",
    "    if i == 5:\n",
    "        break\n",
    "    print(key, \":\", value)\n",
    "\n",
    "\n",
    "print (len(normalized_dict))\n",
    "\n",
    "# # Save the modified data back to a pickle file (optional)\n",
    "# with open(new_db_pickle_file_path, \"wb\") as f:\n",
    "#     pickle.dump(normalized_dict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file 'output.csv' has been created successfully with UTF-8 encoding.\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import csv\n",
    "\n",
    "# Load the pickle file\n",
    "with open(new_db_pickle_file_path, \"rb\") as pkl_file:\n",
    "    data = pickle.load(pkl_file)\n",
    "\n",
    "# Ensure data is a dictionary\n",
    "if isinstance(data, dict):\n",
    "    # Write to CSV with UTF-8 encoding\n",
    "    with open(\"newdb_output.csv\", \"w\", newline=\"\", encoding=\"utf-8\") as csv_file:\n",
    "        writer = csv.writer(csv_file)\n",
    "        writer.writerow([\"Key\", \"Value\"])  # Header\n",
    "        for key, value in data.items():\n",
    "            writer.writerow([key, value])\n",
    "\n",
    "    print(\"CSV file 'output.csv' has been created successfully with UTF-8 encoding.\")\n",
    "else:\n",
    "    print(\"The loaded pickle file does not contain a dictionary.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted key: White Oak Ventures\n",
      "Updated pickle file saved.\n"
     ]
    }
   ],
   "source": [
    "# import pickle\n",
    "\n",
    "# # Load the pickle file\n",
    "# with open(old_db_pickle_file_path, \"rb\") as pkl_file:\n",
    "#     data = pickle.load(pkl_file)\n",
    "\n",
    "# # Ensure data is a dictionary\n",
    "# if isinstance(data, dict):\n",
    "#     key_to_delete = 'White Oak Ventures'  # Replace with the actual key you want to remove\n",
    "    \n",
    "#     # Remove the key if it exists\n",
    "#     if key_to_delete in data:\n",
    "#         del data[key_to_delete]\n",
    "#         print(f\"Deleted key: {key_to_delete}\")\n",
    "#     else:\n",
    "#         print(f\"Key '{key_to_delete}' not found in the dictionary.\")\n",
    "\n",
    "#     # Save the updated dictionary back to the pickle file\n",
    "#     with open(old_db_pickle_file_path, \"wb\") as pkl_file:\n",
    "#         pickle.dump(data, pkl_file)\n",
    "\n",
    "#     print(\"Updated pickle file saved.\")\n",
    "# else:\n",
    "#     print(\"The pickle file does not contain a dictionary.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "# import os\n",
    "\n",
    "# # Folder containing the pickle files\n",
    "# folder_path = r\"E:\\EmailTool-V2\\Barzaan\\email_creator_app\\files\"  # Change this to your actual folder path\n",
    "\n",
    "# # Initialize an empty dictionary to store merged data\n",
    "# merged_data = {}\n",
    "\n",
    "# # Loop through all .pkl files in the folder\n",
    "# for file_name in os.listdir(folder_path):\n",
    "#     if file_name.endswith(\".pkl\"):  # Process only .pkl files\n",
    "#         file_path = os.path.join(folder_path, file_name)\n",
    "        \n",
    "#         # Load the pickle file\n",
    "#         with open(file_path, \"rb\") as pkl_file:\n",
    "#             data = pickle.load(pkl_file)\n",
    "            \n",
    "#             # Ensure the file contains a dictionary\n",
    "#             if isinstance(data, dict):\n",
    "#                 for key, value in data.items():\n",
    "#                     if key not in merged_data:  # Add only if the key is not already present\n",
    "#                         merged_data[key] = value\n",
    "#             else:\n",
    "#                 print(f\"Skipping {file_name}: Not a dictionary.\")\n",
    "\n",
    "# # Save the merged data into a new pickle file\n",
    "# output_file = os.path.join(folder_path, \"merged_data.pkl\")\n",
    "# with open(output_file, \"wb\") as pkl_file:\n",
    "#     pickle.dump(merged_data, pkl_file)\n",
    "\n",
    "# print(f\"Merged pickle file saved as: {output_file}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = [{'title': 'Contact - MassHire Downtown Boston Career Center', 'link': 'https://masshiredowntownboston.org/contact/', 'snippet': ' Boston Office · 75 Federal Street, 3rd Floor Boston, MA 02110 · 617.399.3100 · RESEA Program: resea@masshiredowntownboston.org · Unemployment Insurance: · 877.626. '}, {'title': 'MassHire Downtown Boston Career Center Information - RocketReach', 'link': 'https://rocketreach.co/masshire-downtown-boston-career-center-profile_b406d202fc226471', 'snippet': ' Email Format · Management · Technology Stack · Competitors\\xa0... '}, {'title': 'MassHire Downtown Boston Career Center: Home', 'link': 'https://masshiredowntownboston.org/', 'snippet': ' Empowering Boston Job Seekers & Young Adults 18-24, with Free Cutting-Edge Knowledge and Resources for Your Job Search. '}, {'title': 'American Job Center Finder | CareerOneStop', 'link': 'https://www.careeronestop.org/LocalHelp/AmericanJobCenters/find-american-job-centers-details.aspx?location=Massachusetts&radius=25&centerID=98116&ct=0&y=0&w=0&e=0&locationSelected=0&sortcolumns=Location&sortdirections=ASC&curPage=1&pagesize=10', 'snippet': ' https://masshiredowntownboston.org/. AJC Detail Information. Directions. General Information. Gen Information. E-mail Address, inquiry@masshiredowntownboston. '}, {'title': 'Meet Our Team - MassHire Downtown Boston Career Center', 'link': 'https://masshiredowntownboston.org/aboutus/meet-our-team/', 'snippet': ' 27 Feb 2025  ·  Adalberto Jaimes is a Manager of Economic Opportunity at JVS with over 10 years of financial education and coaching experience. '}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Boston Office · 75 Federal Street, 3rd Floor Boston, MA 02110 · 617.399.3100 · RESEA Program: resea@masshiredowntownboston.org · Unemployment Insurance: · 877.626. '"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f[0]['snippet']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
