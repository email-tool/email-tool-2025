{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "top 5 companies \n",
    "old data\n",
    "5000\n",
    "3000 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from web_email_scrapper_multiEngine import get_email_from_snippet, fetch_yahoo_results, fetch_bing_results\n",
    "import time\n",
    "from datetime import datetime, timedelta\n",
    "import math\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import re\n",
    "# from urllib.parse import urlparse\n",
    "\n",
    "# # Input dictionary\n",
    "# def get_email_pattern(EMAIL):    \n",
    "#     names = [\n",
    "#         {\"first\": \"john\", \"last\": \"smith\"},\n",
    "#         {\"first\": \"jane\", \"last\": \"doe\"},\n",
    "#         {\"first\": \"john\", \"last\": \"doe\"},\n",
    "#         {\"first\": \"first\", \"last\": \"last\"}\n",
    "#     ]\n",
    "    \n",
    "\n",
    "#     email = EMAIL.split(\"@\")[0].strip().lower()\n",
    "\n",
    "#     for name in names:\n",
    "#         first_name = name[\"first\"]\n",
    "#         last_name = name[\"last\"]\n",
    "#         patterns = {\n",
    "#                 # 1. Full Name Variations\n",
    "#                 \"FirstNameLastName\": f\"{first_name}{last_name}\",\n",
    "#                 \"FirstName.LastName\": f\"{first_name}.{last_name}\",\n",
    "#                 \"FirstName_LastName\": f\"{first_name}_{last_name}\",\n",
    "#                 \"FirstName-LastName\": f\"{first_name}-{last_name}\",\n",
    "\n",
    "#                 \"LastNameFirstName\": f\"{last_name}{first_name}\",\n",
    "#                 \"LastName.FirstName\": f\"{last_name}.{first_name}\",\n",
    "#                 \"LastName_FirstName\": f\"{last_name}_{first_name}\",\n",
    "#                 \"LastName-FirstName\": f\"{last_name}-{first_name}\",\n",
    "\n",
    "#                 # 2. First Initial + Last Name\n",
    "#                 \"FirstName1LastName\": f\"{first_name[0]}{last_name}\",\n",
    "#                 \"FirstName1.LastName\": f\"{first_name[0]}.{last_name}\",\n",
    "#                 \"FirstName1_LastName\": f\"{first_name[0]}_{last_name}\",\n",
    "#                 \"FirstName1-LastName\": f\"{first_name[0]}-{last_name}\",\n",
    "\n",
    "#                 # 3. Last Initial + First Name\n",
    "#                 \"LastName1FirstName\": f\"{last_name[0]}{first_name}\",\n",
    "#                 \"LastName1.FirstName\": f\"{last_name[0]}.{first_name}\",\n",
    "#                 \"LastName1_FirstName\": f\"{last_name[0]}_{first_name}\",\n",
    "#                 \"LastName1-FirstName\": f\"{last_name[0]}-{first_name}\",\n",
    "\n",
    "#                 # 4. First Name + Last Initial\n",
    "#                 \"FirstNameLastName1\": f\"{first_name}{last_name[0]}\",\n",
    "#                 \"FirstName.LastName1\": f\"{first_name}.{last_name[0]}\",\n",
    "#                 \"FirstName_LastName1\": f\"{first_name}_{last_name[0]}\",\n",
    "#                 \"FirstName-LastName1\": f\"{first_name}-{last_name[0]}\",\n",
    "\n",
    "#                 # 5. Last Name + First Initial\n",
    "#                 \"LastNameFirstName1\": f\"{last_name}{first_name[0]}\",\n",
    "#                 \"LastName.FirstName1\": f\"{last_name}.{first_name[0]}\",\n",
    "#                 \"LastName_FirstName1\": f\"{last_name}_{first_name[0]}\",\n",
    "#                 \"LastName-FirstName1\": f\"{last_name}-{first_name[0]}\",\n",
    "\n",
    "\n",
    "#                 # 7. First initial + Last Initial\n",
    "#                 \"FirstName1LastName1\": f\"{first_name[0]}{last_name[0]}\",\n",
    "#                 \"FirstName1.LastName1\": f\"{first_name[0]}.{last_name[0]}\",\n",
    "#                 \"FirstName1_LastName1\": f\"{first_name[0]}_{last_name[0]}\",\n",
    "#                 \"FirstName1-LastName1\": f\"{first_name[0]}-{last_name[0]}\",\n",
    "\n",
    "\n",
    "#                 # 6. Only First Name, Last Name, Initials\n",
    "#                 \"FirstName\": first_name,\n",
    "#                 \"LastName\": last_name,\n",
    "#                 \"FirstName1\": first_name[0],\n",
    "#                 \"LastName1\": last_name[0]\n",
    "#             }\n",
    "\n",
    "#         for pattern_name, pattern in patterns.items():\n",
    "#             if pattern == email:\n",
    "#                 return pattern_name\n",
    "#     return \"No matching pattern found\"\n",
    "# # Function to extract email format from snippet\n",
    "\n",
    "\n",
    "# def extract_email(snippet):\n",
    "#     match = re.search(r'[\\w\\.\\[\\]]+@[\\w\\.\\[\\]]+', snippet)  # Extracts email-like patterns\n",
    "#     return match.group(0) if match else \"Not Found\"\n",
    "# # Function to extract accuracy from snippet (if mentioned)\n",
    "# def extract_accuracy(snippet):\n",
    "#     match = re.search(r'(\\d{1,3}\\.\\d+)%', snippet)\n",
    "#     return float(match.group(1)) if match else \"Unknown\"\n",
    "# # Function to extract domain name from URL\n",
    "# def extract_website(url):\n",
    "#     try:\n",
    "#         domain = url.split(\"//\")[1]\n",
    "#         g = domain.split('.')\n",
    "#         g = g[0]+g[1]\n",
    "#     except:\n",
    "#         g = \"NA\"\n",
    "#     return g if g else \"Unknown\"\n",
    "# def get_domain(email):\n",
    "\n",
    "#     try:\n",
    "#         domain = email.split('@')[1]\n",
    "#     except:\n",
    "#         domain =\"NA\"\n",
    "#     return domain\n",
    "\n",
    "\n",
    "# import pandas as pd\n",
    "# import os\n",
    "# import re\n",
    "# # Assuming df is your dataframe and 'snippet' is the column name\n",
    "# def extract_text(text):\n",
    "#     keyword = 'for'\n",
    "#     cleaned_text = text.replace(\"what is email format for \", \"\")\n",
    "#     cleaned_text = cleaned_text.replace(\"what is \", \"\")\n",
    "#     return cleaned_text\n",
    "\n",
    "# # combined_df[\"Company\"] = combined_df[\"Company\"]\n",
    "# # Assuming df is your dataframe and 'snippet' is the column name\n",
    "# def extract_emails(text):\n",
    "#     return re.findall(r'[\\w\\.-]+@[\\w\\.-]+\\.\\w+', str(text))\n",
    "\n",
    "\n",
    "# def createCSV(data,name):\n",
    "#     # Creating DataFrame\n",
    "#     records = []\n",
    "#     for entry in data:\n",
    "#         for result in entry['results']:\n",
    "#             text = (entry['query'])\n",
    "#             # Extract text after \"email format for\"\n",
    "#             company = text.replace(\"what is email format for\", \"\").strip()\n",
    "#             company = company.replace(\"+\", \" \").strip()\n",
    "#             website = extract_website(result['link'])\n",
    "#             engine = (entry['engine'])\n",
    "#             email = extract_emails(result['snippet'])\n",
    "#             accuracy = extract_accuracy(result['snippet'])\n",
    "            \n",
    "#             snippet = result['snippet']\n",
    "#             query = company\n",
    "#             records.append({\"company\":query,\"Website\": website, \"Email\": email, \"Engine\":engine, \"Accuracy\": accuracy, \"Snippet\": snippet})\n",
    "\n",
    "#     df = pd.DataFrame(records)\n",
    "#     df[\"email pattern\"] = df[\"Email\"].apply(get_email_pattern)\n",
    "#     df.to_csv(name)\n",
    "#     return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create DataFrames\n",
    "# df1_1 = pd.read_csv(r'/Users/sumanverma/Documents/Work/Email_tool/email_creator_app/automatic_email_format/merged_data.csv')\n",
    "\n",
    "# df2_1 = pd.read_excel(r'//Users/sumanverma/Documents/Work/Email_tool/email_creator_app/automatic_email_format/tool-test-data-10Feb.xlsx')\n",
    "\n",
    "# # Find unique values in column 'A'\n",
    "# unique_values = df1_1['company'].unique()\n",
    "\n",
    "# # Create a new DataFrame with unique values\n",
    "# df1 = pd.DataFrame(unique_values, columns=['company'])\n",
    "# df1 = df1.reset_index(drop=True)\n",
    "# df1 = df1.drop_duplicates(subset=['company']).reset_index(drop=True)\n",
    "# df1 = pd.DataFrame(df1['company'].unique(), columns=['company'])\n",
    "\n",
    "\n",
    "# # Find unique values in column 'A'\n",
    "# unique_values = df2_1['Company'].unique()\n",
    "\n",
    "# # Create a new DataFrame with unique values\n",
    "# df2 = pd.DataFrame(unique_values, columns=['Company'])\n",
    "# df2 = df2.reset_index(drop=True)\n",
    "# df2 = df2.drop_duplicates(subset=['Company']).reset_index(drop=True)\n",
    "# df2 = pd.DataFrame(df2['Company'].unique(), columns=['Company'])\n",
    "\n",
    "# # Create a new column with spaces removed\n",
    "# df2['Company_Combined'] = df2['Company'].str.replace(' ', '', regex=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import glob\n",
    "\n",
    "# # Path to CSV files (Modify this to the correct folder)\n",
    "# csv_files = glob.glob(\"/Users/sumanverma/Documents/Work/Email_tool/email_creator_app/automatic_email_format/kk/*.csv\")  # Reads all CSVs in the folder\n",
    "\n",
    "# # Read and combine all CSV files into one DataFrame\n",
    "# df_list = [pd.read_csv(file) for file in csv_files]  # Read all CSVs\n",
    "# combined_df = pd.concat(df_list, ignore_index=True)  # Merge into one DataFrame\n",
    "\n",
    "# # Save to a new CSV file (optional)\n",
    "# combined_df.to_csv(\"merged_data.csv\", index=False)\n",
    "# print (combined_df.shape)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# import pandas as pd\n",
    "\n",
    "# # First DataFrame (Company Names with and without spaces)\n",
    "# df1 = df2\n",
    "# df1['Company_Combined'] = df1['Company'].str.replace(' ', '', regex=False)\n",
    "\n",
    "# # Second DataFrame (Company Info with No Spaces)\n",
    "\n",
    "\n",
    "# # Step 1: Extract company names from df2 by removing 'what is email format for '\n",
    "# combined_df['company_cleaned'] = combined_df['company'].str.replace('what is email format for ', '', regex=False)\n",
    "\n",
    "# # Step 2: Merge df1 (with spaces removed) and df2 (cleaned company names)\n",
    "# combined_df = combined_df.merge(df1, left_on='company_cleaned', right_on='Company_Combined', how='left')\n",
    "# combined_df.reset_index(drop=True, inplace=True)\n",
    "# # Step 3: Drop unnecessary columns and keep relevant ones\n",
    "# # combined_df = combined_df[['company', 'Company', 'Website', 'Email']]\n",
    "\n",
    "# # Display the final mapped DataFrame\n",
    "# print(combined_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'combined_output_missing'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "\n",
    "csv_file = r'/Users/sumanverma/Documents/Work/Email_tool/email_creator_app/automatic_email_format/combined_output_missing.csv'\n",
    "\n",
    "\n",
    "                                # Get file name without extension\n",
    "file_name_no_ext = os.path.splitext(os.path.basename(csv_file))[0]\n",
    "file_name_no_ext\n",
    "\n",
    "# Load CSV\n",
    "# df = pd.read_csv(csv_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(473, 2)\n"
     ]
    }
   ],
   "source": [
    "# Create DataFrame\n",
    "dfw = pd.DataFrame(combined_df)\n",
    "\n",
    "# Group by 'Company' and check if all emails are empty for each company\n",
    "df_grouped = dfw.groupby(\"Company\")[\"email_list\"].sum()  # Sum will concatenate lists\n",
    "df_no_email = df_grouped[df_grouped.apply(len) == 0].reset_index()\n",
    "\n",
    "# Display result\n",
    "print(df_no_email.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(22802, 7)\n",
      "                          Company Accuracy  \\\n",
      "1   ontario health | sant ontario  Unknown   \n",
      "\n",
      "                                             Website  Engine  \\\n",
      "1  leadiqcom/c/ontario-health--sant%C3%A9-ontario...  Google   \n",
      "\n",
      "                         email                     email_list  \\\n",
      "1  First.Last@ontariohealth.ca  [First.Last@ontariohealth.ca]   \n",
      "\n",
      "                          email_format  \n",
      "1  FirstName.LastName@ontariohealth.ca  \n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "condition = \"No matching pattern found\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import re\n",
    "\n",
    "# df = pd.read_csv(r'/Users/sumanverma/Documents/Work/Email_tool/email_creator_app/automatic_email_format/FirstBatch-dddd.csv')\n",
    "# # Function to extract domain from email\n",
    "# # Function to extract domain from email\n",
    "# def extract_domain(email):\n",
    "#     if isinstance(email, str):  # Ensure it's a string\n",
    "#         match = re.search(r'@([\\w.-]+)', email)\n",
    "#         return match.group(1) if match else \"\"\n",
    "#     return \"\"\n",
    "\n",
    "# # Function to find the best-matching email\n",
    "# def find_best_matching_email(company, emails):\n",
    "#     if not isinstance(emails, list) or len(emails) == 0:  # Ensure it's a valid list\n",
    "#         return None\n",
    "    \n",
    "#     company_cleaned = re.sub(r'[^a-zA-Z0-9]', '', str(company)).lower()  # FIXED\n",
    "#     best_email = None\n",
    "#     best_score = 0\n",
    "\n",
    "#     for email in emails:\n",
    "#         domain = extract_domain(email).split('.')[0]  # Extract domain without TLD\n",
    "#         domain_cleaned = re.sub(r'[^a-zA-Z0-9]', '', domain).lower()\n",
    "\n",
    "#         # Match score: Count overlapping characters\n",
    "#         score = sum(1 for c in domain_cleaned if c in company_cleaned)\n",
    "\n",
    "#         if score > best_score:\n",
    "#             best_score = score\n",
    "#             best_email = email\n",
    "\n",
    "#     return best_email\n",
    "\n",
    "# # Apply function to get best matching email\n",
    "# df[\"best_matching_email\"] = df.apply(lambda row: find_best_matching_email(row[\"company\"], row[\"email_list\"]), axis=1)\n",
    "# df.to_csv(\"CleanedWithScore.csv\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['company', 'email pattern'], dtype='object')\n",
      "Updated CSV saved to: /Users/sumanverma/Documents/Work/Email_tool/email_creator_app/automatic_email_format/CreateEmails_21-23-24v2.csv\n"
     ]
    }
   ],
   "source": [
    "# Path to your CSV file\n",
    "csv_file = r\"/Users/sumanverma/Documents/Work/Email_tool/email_creator_app/files/created_emails/always_test_no_change_output.csv\"\n",
    "\n",
    "csv_file = r'OnlyEmailPatterns_23FebV2.csv'\n",
    "import difflib\n",
    "\n",
    "\n",
    "def extract_domain(email_pattern):\n",
    "    \"\"\"Extract domain from the email pattern.\"\"\"\n",
    "    match = re.search(r'@([\\w.-]+)', str(email_pattern))  # Convert to string (handle NaN)\n",
    "    return match.group(1) if match else None\n",
    "\n",
    "def similarity_score(company, domain):\n",
    "    \"\"\"Compare similarity between company name and domain.\"\"\"\n",
    "    company_clean = re.sub(r'[^a-zA-Z0-9]', '', str(company)).lower()\n",
    "    domain_clean = re.sub(r'\\..*$', '', str(domain)).lower()  # Remove TLD (.com, .edu)\n",
    "\n",
    "    score = difflib.SequenceMatcher(None, company_clean, domain_clean).ratio()\n",
    "\n",
    "    if score > 0.8:\n",
    "        return \"High\"\n",
    "    elif score > 0.4:\n",
    "        return \"Medium\"\n",
    "    else:\n",
    "        return \"Low\"\n",
    "\n",
    "# Load CSV\n",
    "df = version2\n",
    "print (df.columns)\n",
    "# Ensure required columns exist\n",
    "if \"company\" in df.columns and \"email pattern\" in df.columns:\n",
    "    # Extract domains and compute similarity\n",
    "    df[\"domain\"] = df[\"email pattern\"].apply(extract_domain)\n",
    "    df[\"match\"] = df.apply(lambda row: similarity_score(row[\"company\"], row[\"domain\"]) if row[\"domain\"] else \"N/A\", axis=1)\n",
    "\n",
    "    # Save back to CSV\n",
    "    output_csv = \"/Users/sumanverma/Documents/Work/Email_tool/email_creator_app/automatic_email_format/CreateEmails_21-23-24v2.csv\"\n",
    "    df.to_csv(output_csv, index=False)\n",
    "\n",
    "    print(f\"Updated CSV saved to: {output_csv}\")\n",
    "else:\n",
    "    print(\"Error: CSV file must contain 'company' and 'email pattern' columns.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2566\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "# Read the pickle file\n",
    "with open(\"/Users/sumanverma/Documents/Work/Email_tool/email_creator_app/files/main_database/email_patterns.pkl\", \"rb\") as file:\n",
    "    data_dict = pickle.load(file)  # Load as a dictionary\n",
    "\n",
    "# Print or use the dictionary\n",
    "print(len(data_dict))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['LastName@healthsourcemso.com']\n"
     ]
    }
   ],
   "source": [
    "d = '1 health source inc.'\n",
    "print((data_dict[d]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# New dictionary to replace existing content\n",
    "new_data = {'10th sfg': 'LastName@soc.mil'}\n",
    "\n",
    "# Replace content by overwriting the file\n",
    "with open(\"/Users/sumanverma/Documents/Work/Email_tool/email_creator_app/files/main_database/email_patterns.pkl\", \"wb\") as file:\n",
    "    pickle.dump(new_data, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                company Company\n",
      "0       what is email format for 060technologysolutions     NaN\n",
      "1               what is email format for 0734properties     NaN\n",
      "2                 what is email format for 0xb8networks     NaN\n",
      "3                       what is email format for 1&fund     NaN\n",
      "4     what is email format for 1bct101stairbornedivi...     NaN\n",
      "...                                                 ...     ...\n",
      "1107                      what is email format for a.j.    a.j.\n",
      "1108  what is email format for a.j.baynesfreightcont...     NaN\n",
      "1109         what is email format for a.j.manufacturing     NaN\n",
      "1110  what is email format for a.j.rosemanufacturingco.     NaN\n",
      "1111           what is email format for a.j.tuckcompany     NaN\n",
      "\n",
      "[1112 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# Create DataFrames\n",
    "df1_1 = pd.read_csv(r'/Users/sumanverma/Documents/Work/Email_tool/email_creator_app/automatic_email_format/merged_data.csv')\n",
    "\n",
    "df2_1 = pd.read_excel(r'//Users/sumanverma/Documents/Work/Email_tool/email_creator_app/automatic_email_format/tool-test-data-10Feb.xlsx')\n",
    "\n",
    "# Find unique values in column 'A'\n",
    "unique_values = df1_1['company'].unique()\n",
    "\n",
    "# Create a new DataFrame with unique values\n",
    "df1 = pd.DataFrame(unique_values, columns=['company'])\n",
    "df1 = df1.reset_index(drop=True)\n",
    "df1 = df1.drop_duplicates(subset=['company']).reset_index(drop=True)\n",
    "df1 = pd.DataFrame(df1['company'].unique(), columns=['company'])\n",
    "\n",
    "\n",
    "# Find unique values in column 'A'\n",
    "unique_values = df2_1['Company'].unique()\n",
    "\n",
    "# Create a new DataFrame with unique values\n",
    "df2 = pd.DataFrame(unique_values, columns=['Company'])\n",
    "df2 = df2.reset_index(drop=True)\n",
    "df2 = df2.drop_duplicates(subset=['Company']).reset_index(drop=True)\n",
    "df2 = pd.DataFrame(df2['Company'].unique(), columns=['Company'])\n",
    "\n",
    "# Create a new column with spaces removed\n",
    "df2['Company_Combined'] = df2['Company'].str.replace(' ', '', regex=False)\n",
    "\n",
    "# Display the updated DataFrame\n",
    "\n",
    "\n",
    "print (merged_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.to_csv(\"JJ.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(579, 13)"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Function to check if email ends with .com, handling NaN\n",
    "def check_com(email):\n",
    "    if pd.isna(email) or email.strip() == \"\":\n",
    "        return None  # Or False if you prefer\n",
    "    return email.endswith(\".com\")\n",
    "final_created_emails = pd.read_csv(r'/Users/sumanverma/Documents/Work/Email_tool/email_creator_app/CreateEmails_21Feb.csv')\n",
    "\n",
    "# print(final_created_emails.head())\n",
    "\n",
    "final_created_emails = final_created_emails[final_created_emails[\"Email\"].str.strip() != \"\"]  # Remove empty strings\n",
    "\n",
    "# Create flag column (True if .com, False otherwise)\n",
    "final_created_emails[\"valid_com\"] = final_created_emails[\"Email\"].apply(check_com)\n",
    "\n",
    "(final_created_emails[final_created_emails['valid_com']== True].shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(829, 10)"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Function to check if email ends with .com, handling NaN\n",
    "def check_com(email):\n",
    "    if pd.isna(email) or email.strip() == \"\":\n",
    "        return None  # Or False if you prefer\n",
    "    return email.endswith(\".com\")\n",
    "final_created_emails = pd.read_csv(r'/Users/sumanverma/Documents/Work/Email_tool/email_creator_app/files/created_emails/tool-test-data-21Feb_output.csv')\n",
    "\n",
    "# print(final_created_emails.head())\n",
    "\n",
    "final_created_emails = final_created_emails[final_created_emails[\"Email\"].str.strip() != \"\"]  # Remove empty strings\n",
    "\n",
    "# Create flag column (True if .com, False otherwise)\n",
    "final_created_emails[\"valid_com\"] = final_created_emails[\"Email\"].apply(check_com)\n",
    "\n",
    "final_created_emails = final_created_emails[['Company', 'Contact Name', 'First Name',\n",
    "       'Last Name', 'Designation', 'Location', 'Industry', 'Mailer_Status',\n",
    "       'Email', 'valid_com']]\n",
    "\n",
    "(final_created_emails[final_created_emails['valid_com']== True].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company</th>\n",
       "      <th>Contact Name</th>\n",
       "      <th>First Name</th>\n",
       "      <th>Last Name</th>\n",
       "      <th>Designation</th>\n",
       "      <th>Location</th>\n",
       "      <th>Industry</th>\n",
       "      <th>Mailer_Status</th>\n",
       "      <th>Email</th>\n",
       "      <th>valid_com</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>060 technology solutions</td>\n",
       "      <td>Vince Rowland</td>\n",
       "      <td>vince</td>\n",
       "      <td>rowland</td>\n",
       "      <td>apple technician, account manager</td>\n",
       "      <td>hutchinson, ks</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>vince@060tech.com</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0734 properties</td>\n",
       "      <td>Marcus Roberson</td>\n",
       "      <td>marcus</td>\n",
       "      <td>roberson</td>\n",
       "      <td>co-owner</td>\n",
       "      <td>denver, co</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>mroberson@tesla.com</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0xb8 networks</td>\n",
       "      <td>Nicholas Kukla</td>\n",
       "      <td>nicholas</td>\n",
       "      <td>kukla</td>\n",
       "      <td>it and operations consultant</td>\n",
       "      <td>new york city, ny</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1 &amp; fund</td>\n",
       "      <td>Evan Dodge</td>\n",
       "      <td>evan</td>\n",
       "      <td>dodge</td>\n",
       "      <td>vice president of product</td>\n",
       "      <td>montrose, co</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1 bct 101st airborne division air assault</td>\n",
       "      <td>Tyler Ogden</td>\n",
       "      <td>tyler</td>\n",
       "      <td>ogden</td>\n",
       "      <td>brigade medical operations ncoic</td>\n",
       "      <td>fort campbell, tn</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2364</th>\n",
       "      <td>ads tactical</td>\n",
       "      <td>Alan Downs</td>\n",
       "      <td>alan</td>\n",
       "      <td>downs</td>\n",
       "      <td>operations manager</td>\n",
       "      <td>virginia beach, va</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2365</th>\n",
       "      <td>adscis laboratory</td>\n",
       "      <td>Joseph Harwood</td>\n",
       "      <td>joseph</td>\n",
       "      <td>harwood</td>\n",
       "      <td>director of operations</td>\n",
       "      <td>albany, ny</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2366</th>\n",
       "      <td>adsgency ai techstars 23</td>\n",
       "      <td>Tong Li</td>\n",
       "      <td>tong</td>\n",
       "      <td>li</td>\n",
       "      <td>full stack engineer</td>\n",
       "      <td>honolulu, hi</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2367</th>\n",
       "      <td>adsprout advertising</td>\n",
       "      <td>Isabelle Cunis</td>\n",
       "      <td>isabelle</td>\n",
       "      <td>cunis</td>\n",
       "      <td>data scientist</td>\n",
       "      <td>denver, co</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2368</th>\n",
       "      <td>adt pizza</td>\n",
       "      <td>David Lockwood</td>\n",
       "      <td>david</td>\n",
       "      <td>lockwood</td>\n",
       "      <td>director of operations</td>\n",
       "      <td>sparta, tn</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2369 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        Company     Contact Name First Name  \\\n",
       "0                      060 technology solutions    Vince Rowland      vince   \n",
       "1                               0734 properties  Marcus Roberson     marcus   \n",
       "2                                 0xb8 networks   Nicholas Kukla   nicholas   \n",
       "3                                      1 & fund       Evan Dodge       evan   \n",
       "4     1 bct 101st airborne division air assault      Tyler Ogden      tyler   \n",
       "...                                         ...              ...        ...   \n",
       "2364                               ads tactical       Alan Downs       alan   \n",
       "2365                          adscis laboratory   Joseph Harwood     joseph   \n",
       "2366                   adsgency ai techstars 23          Tong Li       tong   \n",
       "2367                       adsprout advertising   Isabelle Cunis   isabelle   \n",
       "2368                                  adt pizza   David Lockwood      david   \n",
       "\n",
       "     Last Name                        Designation            Location  \\\n",
       "0      rowland  apple technician, account manager      hutchinson, ks   \n",
       "1     roberson                           co-owner          denver, co   \n",
       "2        kukla       it and operations consultant   new york city, ny   \n",
       "3        dodge          vice president of product        montrose, co   \n",
       "4        ogden   brigade medical operations ncoic   fort campbell, tn   \n",
       "...        ...                                ...                 ...   \n",
       "2364     downs                 operations manager  virginia beach, va   \n",
       "2365   harwood             director of operations          albany, ny   \n",
       "2366        li                full stack engineer        honolulu, hi   \n",
       "2367     cunis                     data scientist          denver, co   \n",
       "2368  lockwood             director of operations          sparta, tn   \n",
       "\n",
       "      Industry  Mailer_Status                Email valid_com  \n",
       "0          NaN            NaN    vince@060tech.com      True  \n",
       "1          NaN            NaN  mroberson@tesla.com      True  \n",
       "2          NaN            NaN                  NaN       NaN  \n",
       "3          NaN            NaN                  NaN       NaN  \n",
       "4          NaN            NaN                  NaN       NaN  \n",
       "...        ...            ...                  ...       ...  \n",
       "2364       NaN            NaN                  NaN       NaN  \n",
       "2365       NaN            NaN                  NaN       NaN  \n",
       "2366       NaN            NaN                  NaN       NaN  \n",
       "2367       NaN            NaN                  NaN       NaN  \n",
       "2368       NaN            NaN                  NaN       NaN  \n",
       "\n",
       "[2369 rows x 10 columns]"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "final_created_emails.to_csv(\"CreateEmails_21-10pmFeb.csv\", index=False)\n",
    "\n",
    "final_created = pd.read_csv(r'CreateEmails_21-10pmFeb.csv')\n",
    "final_created\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered file saved: /Users/sumanverma/Documents/Work/Email_tool/email_creator_app/files/created_emails/filtered_Baltimore, MD-B2B-23152.xlsx\n",
      "Filtered file saved: /Users/sumanverma/Documents/Work/Email_tool/email_creator_app/files/created_emails/filtered_Fresno, CA-10000.xlsx\n",
      "No unknown email patterns found for complete.xlsx. No file saved.\n",
      "Filtered file saved: /Users/sumanverma/Documents/Work/Email_tool/email_creator_app/files/created_emails/filtered_Colorado Springs, CO Seggrigation _.xlsx\n",
      "Filtered file saved: /Users/sumanverma/Documents/Work/Email_tool/email_creator_app/files/created_emails/filtered_Austin, Tx seggrigation_1.xlsx\n",
      "Filtered file saved: /Users/sumanverma/Documents/Work/Email_tool/email_creator_app/files/created_emails/filtered_Colorado.xlsx\n",
      "No matching df2 file found for Fresno, CA-test.xlsx, skipping...\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Define folder paths\n",
    "df1_folder = r\"/Users/sumanverma/Documents/Work/Email_tool/database_source_files\"\n",
    "df2_folder = r\"/Users/sumanverma/Documents/Work/Email_tool/email_creator_app/files/database_output_files\"\n",
    "output_folder = r\"/Users/sumanverma/Documents/Work/Email_tool/email_creator_app/files/created_emails\"\n",
    "\n",
    "# Ensure output folder exists\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# Get all df1 and df2 files\n",
    "df1_files = [f for f in os.listdir(df1_folder) if f.endswith(('.csv', '.xlsx'))]\n",
    "df2_files = [f for f in os.listdir(df2_folder) if f.endswith(('.csv', '.xlsx'))]\n",
    "\n",
    "# Process each df1 file\n",
    "for df1_file in df1_files:\n",
    "    # Get file name length (without extension)\n",
    "    df1_base = os.path.splitext(df1_file)[0]\n",
    "    df1_length = len(df1_base)\n",
    "\n",
    "    # Find matching df2 file by comparing only first X characters\n",
    "    matching_df2_file = next((f for f in df2_files if os.path.splitext(f)[0][:df1_length] == df1_base), None)\n",
    "\n",
    "    if not matching_df2_file:\n",
    "        print(f\"No matching df2 file found for {df1_file}, skipping...\")\n",
    "        continue\n",
    "\n",
    "    # Read df1 file\n",
    "    df1_path = os.path.join(df1_folder, df1_file)\n",
    "    if df1_file.endswith('.csv'):\n",
    "        df1 = pd.read_csv(df1_path)\n",
    "    else:\n",
    "        df1 = pd.read_excel(df1_path)\n",
    "\n",
    "    # Read df2 file\n",
    "    df2_path = os.path.join(df2_folder, matching_df2_file)\n",
    "    if matching_df2_file.endswith('.csv'):\n",
    "        df2 = pd.read_csv(df2_path)\n",
    "    else:\n",
    "        df2 = pd.read_excel(df2_path)\n",
    "\n",
    "    # Ensure required columns exist\n",
    "    if \"Company\" not in df1.columns or \"company\" not in df2.columns or \"email pattern\" not in df2.columns:\n",
    "        print(f\"Skipping {df1_file} due to missing columns.\")\n",
    "        continue\n",
    "\n",
    "    # Identify companies with unknown email patterns in df2\n",
    "    unknown_companies = df2[df2[\"email pattern\"].str.startswith(\"unknown@\")][\"company\"]\n",
    "\n",
    "    # Filter df1 based on these companies\n",
    "    filtered_df1 = df1[df1[\"Company\"].isin(unknown_companies)]\n",
    "\n",
    "    # Save output if any rows are found\n",
    "    if not filtered_df1.empty:\n",
    "        output_path = os.path.join(output_folder, f\"filtered_{df1_file}\")\n",
    "        if df1_file.endswith('.csv'):\n",
    "            filtered_df1.to_csv(output_path, index=False)\n",
    "        else:\n",
    "            filtered_df1.to_excel(output_path, index=False)\n",
    "\n",
    "        print(f\"Filtered file saved: {output_path}\")\n",
    "    else:\n",
    "        print(f\"No unknown email patterns found for {df1_file}. No file saved.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file name split_part_7_output.csv\n",
      "(39943, 11)\n",
      "----------- (1446, 11)\n",
      "file name split_part_2_output.csv\n",
      "(39955, 11)\n",
      "----------- (2871, 11)\n",
      "file name split_part_8_output.csv\n",
      "(14583, 11)\n",
      "----------- (569, 11)\n",
      "file name split_part_5_output.csv\n",
      "(39961, 11)\n",
      "----------- (1491, 11)\n",
      "file name split_part_3_output.csv\n",
      "(39954, 11)\n",
      "----------- (1411, 11)\n",
      "file name split_part_6_output.csv\n",
      "(39956, 11)\n",
      "----------- (1489, 11)\n",
      "file name split_part_1_output.csv\n",
      "(39953, 11)\n",
      "----------- (3678, 11)\n",
      "file name split_part_4_output.csv\n",
      "(39949, 11)\n",
      "----------- (1513, 11)\n",
      "Filtered CSV saved to: filtered_output.csv\n",
      "(14468, 11)\n",
      "    Unnamed: 0  Srl No                                   Company  \\\n",
      "39          39  663323  tucker rocky distributing/biker's choice   \n",
      "46          46  663338                        anderson dentistry   \n",
      "\n",
      "     Contact Name First Name Last Name               Designation  \\\n",
      "39  Debbie Conner     debbie    conner  team selling coordinator   \n",
      "46   Jessica Neal    jessica      neal       hygiene coordinator   \n",
      "\n",
      "                        Location  Industry  Mailer_Status  \\\n",
      "39  keller, texas, united states       NaN            NaN   \n",
      "46   dallas-fort worth metroplex       NaN            NaN   \n",
      "\n",
      "                      Email  \n",
      "39  dconner@tuckerrocky.com  \n",
      "46  jessica@atowndental.com  \n",
      "        Unnamed: 0  Srl No                                   Company  \\\n",
      "39              39  663323  tucker rocky distributing/biker's choice   \n",
      "46              46  663338                        anderson dentistry   \n",
      "57              57  663352                             madden dental   \n",
      "127            127  663452             isabella shipping company ltd   \n",
      "199            199  663540                  texas cash and pawn, llc   \n",
      "...            ...     ...                                       ...   \n",
      "294188       39934  437629                    hertz first rent a car   \n",
      "294193       39939  437643                    traverse health clinic   \n",
      "294197       39943  437651                       lincare respiratory   \n",
      "294215       39961  437698                 forward hospitality group   \n",
      "294230       39976  437749    the latino medical student association   \n",
      "\n",
      "               Contact Name First Name Last Name  \\\n",
      "39            Debbie Conner     debbie    conner   \n",
      "46             Jessica Neal    jessica      neal   \n",
      "57            Sylvia Alonzo     sylvia    alonzo   \n",
      "127     Sandra Segura Ramos     sandra     ramos   \n",
      "199             Maria Ponce      maria     ponce   \n",
      "...                     ...        ...       ...   \n",
      "294188       Brittney Gayle   brittney     gayle   \n",
      "294193      Gabrielle Weber  gabrielle     weber   \n",
      "294197        Shelly McNair     shelly    mcnair   \n",
      "294215          Grace Hayes      grace     hayes   \n",
      "294230        Jordan Mantor     jordan    mantor   \n",
      "\n",
      "                            Designation  \\\n",
      "39             team selling coordinator   \n",
      "46                  hygiene coordinator   \n",
      "57              appointment coordinator   \n",
      "127               logistics coordinator   \n",
      "199     customer service representative   \n",
      "...                                 ...   \n",
      "294188  customer service representative   \n",
      "294193  integrated services coordinator   \n",
      "294197  customer service representative   \n",
      "294215                          barback   \n",
      "294230                event coordinator   \n",
      "\n",
      "                                      Location  Industry  Mailer_Status  \\\n",
      "39                keller, texas, united states       NaN            NaN   \n",
      "46                 dallas-fort worth metroplex       NaN            NaN   \n",
      "57               houston, texas, united states       NaN            NaN   \n",
      "127                            greater houston       NaN            NaN   \n",
      "199            corsicana, texas, united states       NaN            NaN   \n",
      "...                                        ...       ...            ...   \n",
      "294188        detroit, michigan, united states       NaN            NaN   \n",
      "294193  traverse city, michigan, united states       NaN            NaN   \n",
      "294197         youngstown, ohio, united states       NaN            NaN   \n",
      "294215                       greater cleveland       NaN            NaN   \n",
      "294230           columbus, ohio, united states       NaN            NaN   \n",
      "\n",
      "                               Email  \n",
      "39           dconner@tuckerrocky.com  \n",
      "46           jessica@atowndental.com  \n",
      "57                salonzo@madden.com  \n",
      "127     sandra@houseofisabella.co.uk  \n",
      "199     ponce@topcashpawnandloan.com  \n",
      "...                              ...  \n",
      "294188       brittney.gayle@hertz.se  \n",
      "294193        gweber@traversehcc.org  \n",
      "294197           smcnair@lincare.com  \n",
      "294215           grace@forwardhg.com  \n",
      "294230            jmantor@thelaa.org  \n",
      "\n",
      "[14468 rows x 11 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "def combine_and_filter_csv(folder_path, output_file):\n",
    "    all_files = [f for f in os.listdir(folder_path) if f.endswith('.csv')]\n",
    "    df_list = []\n",
    "\n",
    "    # Read all CSV files and combine into one DataFrame\n",
    "    for file in all_files:\n",
    "\n",
    "        print (\"file name\", file)\n",
    "        file_path = os.path.join(folder_path, file)\n",
    "        df = pd.read_csv(file_path)\n",
    "        df_list.append(df)\n",
    "\n",
    "        df['Email'] = df['Email'].fillna(\"NA\")\n",
    "\n",
    "        print (df.shape)\n",
    "        print   ( '-----------',   df[df['Email'] != \"NA\"].shape)\n",
    "\n",
    "    \n",
    "    combined_df = pd.concat(df_list, ignore_index=True)\n",
    "\n",
    "    # Filter rows where 'email' column is not empty\n",
    "    filtered_df = combined_df\n",
    "    filtered_df =filtered_df[(filtered_df['Email'].str.strip() != \"NA\")]\n",
    "    # Save the cleaned data to a new CSV\n",
    "    filtered_df.to_csv(output_file, index=False)\n",
    "    print(f\"Filtered CSV saved to: {output_file}\")\n",
    "    print (filtered_df.shape)\n",
    "    print (filtered_df.head(2))\n",
    "    return filtered_df\n",
    "\n",
    "# Example usage\n",
    "filtered_df = combine_and_filter_csv(r\"/Users/sumanverma/Documents/Work/Email_tool/email_creator_app/files/created_emails\", \"filtered_output.csv\")\n",
    "\n",
    "columns = ['unnamed: 0', 'srl no', 'company', 'contact name', 'first name',\n",
    "       'last name', 'designation', 'location', 'industry', 'mailer_status',\n",
    "       'email', 'domain', 'match']\n",
    "\n",
    "from get_email_flags import get_flags\n",
    "output_csv = f\"/Users/sumanverma/Documents/Work/Email_tool/email_creator_app/automatic_email_format/EmailResults-{str(datetime.now())[:10]}.csv\"\n",
    "print (filtered_df)\n",
    "df = get_flags(filtered_df,'email')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(output_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_email_pattern(EMAIL):    \n",
    "    names = [\n",
    "        {\"first\": \"john\", \"last\": \"smith\"},\n",
    "        {\"first\": \"jane\", \"last\": \"doe\"},\n",
    "        {\"first\": \"first\", \"last\": \"last\"}\n",
    "    \n",
    "    ]\n",
    "    \n",
    "    try:\n",
    "        email = EMAIL.split(\"@\")[0].strip().lower()\n",
    "\n",
    "        domain = EMAIL.split(\"@\")[1].strip().lower()\n",
    "    except:\n",
    "        email = \"NA\"\n",
    "        domain =\"NA\"\n",
    "\n",
    "    \n",
    "    for name in names:\n",
    "        first_name = name[\"first\"]\n",
    "        last_name = name[\"last\"]\n",
    "        \n",
    "        patterns = {\n",
    "            \"FirstName\": first_name,\n",
    "            \"LastName\": last_name,\n",
    "            \"FirstName.LastName\": f\"{first_name}.{last_name}\",\n",
    "            \"FirstName_LastName\": f\"{first_name}_{last_name}\",\n",
    "            \"LastName.FirstName\": f\"{last_name}.{first_name}\",\n",
    "            \"LastName_FirstName\": f\"{last_name}_{first_name}\",\n",
    "            \"LastName.FirstName1\": f\"{last_name}.{first_name[0]}\",\n",
    "            \"FirstNameLastName\": f\"{first_name}{last_name}\",\n",
    "            \"LastNameFirstName\": f\"{last_name}{first_name}\",\n",
    "            \"FirstName-LastName\": f\"{first_name}-{last_name}\",\n",
    "            \"LastName-FirstName\": f\"{last_name}-{first_name}\",\n",
    "            \"FirstName1LastName\": f\"{first_name[0]}{last_name}\",\n",
    "            \"FirstNameLastName1\": f\"{first_name}{last_name[0]}\",\n",
    "            \"LastName1FirstName\": f\"{last_name[0]}{first_name}\",\n",
    "            \"LastNameFirstName1\": f\"{last_name}{first_name[0]}\",\n",
    "            \"FirstName1.LastName\": f\"{first_name[0]}.{last_name}\",\n",
    "            \"LastName1.FirstName\": f\"{last_name[0]}.{first_name}\",\n",
    "            \"FirstName.LastName1\": f\"{first_name}.{last_name[0]}\",\n",
    "            \"FirstName1_LastName\": f\"{first_name[0]}_{last_name}\",\n",
    "            \"LastName1_FirstName\": f\"{last_name[0]}_{first_name}\",\n",
    "            \"FirstName_LastName1\": f\"{first_name}_{last_name[0]}\"\n",
    "        }\n",
    "        \n",
    "        for pattern_name, pattern in patterns.items():\n",
    "            if pattern == email:\n",
    "                return pattern_name\n",
    "    \n",
    "    return \"NA\"\n",
    "# Function to extract full email format after \"email formats: 1.\"\n",
    "def extract_email_format(snippet):\n",
    "    if not isinstance(snippet, str):\n",
    "        return []\n",
    "\n",
    "    pattern = r\"email formats:\\s*1\\.\\s*([^()]+@[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,})\"\n",
    "    match = re.search(pattern, snippet)\n",
    "\n",
    "    return [match.group(1).strip()] if match else []\n",
    "\n",
    "# Function to extract actual email addresses\n",
    "def extract_emails(snippet):\n",
    "    if not isinstance(snippet, str):\n",
    "        return []\n",
    "\n",
    "    emails = re.findall(r'[\\w\\.-]+@[\\w\\.-]+\\.\\w+', snippet)  # Extracts actual emails\n",
    "    return emails if emails else []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>company</th>\n",
       "      <th>website</th>\n",
       "      <th>email_list</th>\n",
       "      <th>engine</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>snippet</th>\n",
       "      <th>domain</th>\n",
       "      <th>match</th>\n",
       "      <th>email_formats_list</th>\n",
       "      <th>email_patterns_list</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>city of virginia beach-skillquest</td>\n",
       "      <td>hsvirginiabeach</td>\n",
       "      <td>['foiacouncil@dls.virginia.gov']</td>\n",
       "      <td>Google</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>The Council may be contacted by e-mail at foi...</td>\n",
       "      <td>dls.virginia.gov</td>\n",
       "      <td>Low</td>\n",
       "      <td>['foiacouncil@dls.virginia.gov']</td>\n",
       "      <td>['No matching pattern found']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>city of virginia beach-skillquest</td>\n",
       "      <td>rocketreachco/department-of-behavioral-health-...</td>\n",
       "      <td>['last@dbhds.virginia.gov']</td>\n",
       "      <td>Google</td>\n",
       "      <td>99.0</td>\n",
       "      <td>Department of Behavioral Health and Developme...</td>\n",
       "      <td>dbhds.virginia.gov</td>\n",
       "      <td>Low</td>\n",
       "      <td>[\"first '.' last@dbhds.virginia.gov\", 'last@db...</td>\n",
       "      <td>['No matching pattern found', 'No matching pat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>city of virginia beach human services</td>\n",
       "      <td>hsvirginiabeach</td>\n",
       "      <td>['foiacouncil@dls.virginia.gov']</td>\n",
       "      <td>Google</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>The Council may be contacted by e-mail at foi...</td>\n",
       "      <td>dls.virginia.gov</td>\n",
       "      <td>Low</td>\n",
       "      <td>['foiacouncil@dls.virginia.gov']</td>\n",
       "      <td>['No matching pattern found']</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                company  \\\n",
       "0           1      city of virginia beach-skillquest   \n",
       "1           2      city of virginia beach-skillquest   \n",
       "2           6  city of virginia beach human services   \n",
       "\n",
       "                                             website  \\\n",
       "0                                    hsvirginiabeach   \n",
       "1  rocketreachco/department-of-behavioral-health-...   \n",
       "2                                    hsvirginiabeach   \n",
       "\n",
       "                         email_list  engine accuracy  \\\n",
       "0  ['foiacouncil@dls.virginia.gov']  Google  Unknown   \n",
       "1       ['last@dbhds.virginia.gov']  Google     99.0   \n",
       "2  ['foiacouncil@dls.virginia.gov']  Google  Unknown   \n",
       "\n",
       "                                             snippet              domain  \\\n",
       "0   The Council may be contacted by e-mail at foi...    dls.virginia.gov   \n",
       "1   Department of Behavioral Health and Developme...  dbhds.virginia.gov   \n",
       "2   The Council may be contacted by e-mail at foi...    dls.virginia.gov   \n",
       "\n",
       "  match                                 email_formats_list  \\\n",
       "0   Low                   ['foiacouncil@dls.virginia.gov']   \n",
       "1   Low  [\"first '.' last@dbhds.virginia.gov\", 'last@db...   \n",
       "2   Low                   ['foiacouncil@dls.virginia.gov']   \n",
       "\n",
       "                                 email_patterns_list  \n",
       "0                      ['No matching pattern found']  \n",
       "1  ['No matching pattern found', 'No matching pat...  \n",
       "2                      ['No matching pattern found']  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filter_df= pd.read_csv(\"filterdataemails.csv\")\n",
    "filter_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0                            company          website  \\\n",
      "0           1  city of virginia beach-skillquest  hsvirginiabeach   \n",
      "\n",
      "                         email_list  engine accuracy  \\\n",
      "0  ['foiacouncil@dls.virginia.gov']  Google  Unknown   \n",
      "\n",
      "                                             snippet            domain match  \\\n",
      "0   The Council may be contacted by e-mail at foi...  dls.virginia.gov   Low   \n",
      "\n",
      "               email_formats_list email_patterns_list  \n",
      "0  [foiacouncil@dls.virginia.gov]   [Unknown Pattern]  \n",
      "(53590, 11)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# Function to identify email format\n",
    "def get_email_pattern(email):\n",
    "    if not isinstance(email, str) or \"@\" not in email:\n",
    "        return \"NA\"\n",
    "\n",
    "\n",
    "    # print (\"*\"*80)\n",
    "    email_prefix = email.split(\"@\")[0].strip().lower()\n",
    "    try:\n",
    "        domain = email.split(\"@\")[1].strip().lower()\n",
    "    except:\n",
    "        domain = \"NA\"\n",
    "    # print (email_prefix)\n",
    "    email_prefix = email_prefix.replace(\" '.' \", \".\").replace(\" '-' \", \"-\").replace(\" '_' \", \"_\").replace('first_initial', 'f').replace('last_initial', 'l').replace(\"filast\",\"flast\")\n",
    "    email_prefix = email_prefix.replace(\" \", \"\")\n",
    "    # print (email_prefix)\n",
    "    # print (\"*\"*80,\"\\n\")\n",
    "    # Remove spaces and normalize format\n",
    "    email_prefix = re.sub(r\"\\s+\", \"\", email_prefix)\n",
    "\n",
    "    # Define name variations\n",
    "    names = [\n",
    "        {\"first\": \"john\", \"last\": \"smith\"},\n",
    "        {\"first\": \"john\", \"last\": \"doe\"},\n",
    "        {\"first\": \"jane\", \"last\": \"doe\"},\n",
    "        {\"first\": \"first\", \"last\": \"last\"},\n",
    "        {\"first\": \"fir\", \"last\": \"last\"},\n",
    "        {\"first\": \"firstname\", \"last\": \"lastname\"},\n",
    "        {\"first\": \"john\", \"last\": \"doe\",\"middle_name\":\"michael\"}\n",
    "\n",
    "    ]\n",
    "\n",
    "    for name in names:\n",
    "        first_name = name[\"first\"]\n",
    "        last_name = name[\"last\"]\n",
    "        try:\n",
    "            middle_name = name['middle_name']\n",
    "        except:\n",
    "            middle_name = \"\"\n",
    "            patterns = {\n",
    "    \"FirstName\": first_name,\n",
    "    \"LastName\": last_name,\n",
    "\n",
    "    \"FirstInitial\": f\"{first_name[0]}\", \n",
    "    \"LastInitial\": f\"{last_name[0]}\", \n",
    "\n",
    "    \"FirstName.LastName\": f\"{first_name}.{last_name}\",\n",
    "    \"FirstName_LastName\": f\"{first_name}_{last_name}\",\n",
    "    \"FirstName-LastName\": f\"{first_name}-{last_name}\",\n",
    "    \"FirstNameLastName\": f\"{first_name}{last_name}\",\n",
    "\n",
    "    \"LastName.FirstName\": f\"{last_name}.{first_name}\",\n",
    "    \"LastName_FirstName\": f\"{last_name}_{first_name}\",\n",
    "    \"LastName-FirstName\": f\"{last_name}-{first_name}\",\n",
    "    \"LastNameFirstName\": f\"{last_name}{first_name}\",\n",
    "\n",
    "    \"FirstInitialLastName\": f\"{first_name[0]}{last_name}\",\n",
    "    \"FirstInitial.LastName\": f\"{first_name[0]}.{last_name}\",\n",
    "    \"FirstInitial_LastName\": f\"{first_name[0]}_{last_name}\",\n",
    "    \"FirstInitial-LastName\": f\"{first_name[0]}-{last_name}\",\n",
    "\n",
    "    \"FirstInitialLastInitial\": f\"{first_name[0]}{last_name[0]}\",\n",
    "    \"FirstInitial.LastInitial\": f\"{first_name[0]}.{last_name[0]}\",\n",
    "    \"FirstInitial_LastInitial\": f\"{first_name[0]}_{last_name[0]}\",\n",
    "    \"FirstInitial-LastInitial\": f\"{first_name[0]}-{last_name[0]}\",\n",
    "\n",
    "    \"FirstName.LastInitial\": f\"{first_name}.{last_name[0]}\",\n",
    "    \"FirstName_LastInitial\": f\"{first_name}_{last_name[0]}\",\n",
    "    \"FirstName-LastInitial\": f\"{first_name}-{last_name[0]}\",\n",
    "    \"FirstNameLastInitial\": f\"{first_name}{last_name[0]}\",\n",
    "\n",
    "    \"LastName.FirstInitial\": f\"{last_name}.{first_name[0]}\",\n",
    "    \"LastName_FirstInitial\": f\"{last_name}_{first_name[0]}\",\n",
    "    \"LastName-FirstInitial\": f\"{last_name}-{first_name[0]}\",\n",
    "    \"LastNameFirstInitial\": f\"{last_name}{first_name[0]}\",\n",
    "\n",
    "    \"FirstInitialLastNameLastInitial\": f\"{first_name[0]}{last_name}{last_name[0]}\",  # Fixed from FirstInitialLastName1\n",
    "    \"FirstInitialLastName\": f\"{first_name[0]}{last_name}\",  # Fixed from FirstName1LastName\n",
    "    \"FirstNameLastInitial\": f\"{first_name}{last_name[0]}\",  # Fixed from FirstNameLastName1\n",
    "    \"LastInitialFirstName\": f\"{last_name[0]}{first_name}\",  # Fixed from LastName1FirstName\n",
    "    \"LastNameFirstInitial\": f\"{last_name}{first_name[0]}\",  # Fixed from LastNameFirstName1\n",
    "\n",
    "    \"LastInitial.FirstInitial\": f\"{last_name[0]}.{first_name[0]}\",\n",
    "    \"LastInitial-FirstInitial\": f\"{last_name[0]}-{first_name[0]}\",\n",
    "    \"LastInitial_FirstInitial\": f\"{last_name[0]}_{first_name[0]}\",\n",
    "    \"LastInitialFirstInitial\": f\"{last_name[0]}{first_name[0]}\",\n",
    "\n",
    "    \"LastInitial.FirstName\": f\"{last_name[0]}.{first_name}\",\n",
    "    \"LastInitial-FirstName\": f\"{last_name[0]}-{first_name}\",\n",
    "    \"LastInitial_FirstName\": f\"{last_name[0]}_{first_name}\",\n",
    "    \"LastInitialFirstName\": f\"{last_name[0]}{first_name}\",\n",
    "}\n",
    "\n",
    "\n",
    "        for pattern_name, pattern in patterns.items():\n",
    "            if pattern == email_prefix:\n",
    "                return pattern_name + \"@\" + domain\n",
    "\n",
    "    return \"Unknown Pattern\"\n",
    "\n",
    "\n",
    "# Apply both extraction functions to the DataFrame\n",
    "filter_df[\"email_formats_list\"] = filter_df[\"snippet\"].apply(lambda x: extract_email_format(x) + extract_emails(x))\n",
    "filter_df[\"email_patterns_list\"] = filter_df[\"email_formats_list\"].apply(lambda email_list: [get_email_pattern(email) for email in email_list])\n",
    "\n",
    "# Display updated DataFrame\n",
    "print(filter_df.head(1))\n",
    "print (filter_df.shape)\n",
    "\n",
    "\n",
    "# Apply function to each email in the list and store patterns in a new column\n",
    "# df[\"email_patterns_list\"] = df[\"emailemail_list\"].apply(get_email_pattern)\n",
    "# df[df[\"email_patterns_list\"]!= 'Unknown Pattern']\n",
    "# filter_df.to_csv(\"acceeeee.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def select_best_row(group):\n",
    "    for _, row in group.iterrows():\n",
    "        if row[\"email pattern\"] and row[\"email pattern\"] != [\"Unknown Pattern\"]:  \n",
    "            row[\"email pattern\"] = [row[\"email pattern\"][0]]  # Keep only the first pattern\n",
    "            return row\n",
    "    return group.iloc[0]  # If no valid email pattern, return the first row\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rawdatatoday.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "yesterday_data = pd.read_csv('rawdatatoday.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_email_patterns_only(yesterday_data, name):\n",
    "    yesterday_data.columns = yesterday_data.columns.str.lower()\n",
    "    yesterday_data = yesterday_data[['company', 'website', 'snippet']]\n",
    "    yesterday_data = yesterday_data.drop_duplicates(keep=\"first\").reset_index(drop=True)\n",
    "    yesterday_data[\"email_formats_list\"] = yesterday_data[\"snippet\"].apply(lambda x: extract_email_format(x) + extract_emails(x))\n",
    "    yesterday_data[\"email pattern\"] = yesterday_data[\"email_formats_list\"].apply(lambda email_list: [get_email_pattern(email) for email in email_list])\n",
    "    # Apply the function to each company group\n",
    "    filtered_df = yesterday_data.groupby(\"company\", group_keys=False).apply(select_best_row)\n",
    "\n",
    "    # Reset index\n",
    "    filtered_df.reset_index(drop=True, inplace=True)\n",
    "    filtered_df[\"company\"] = filtered_df[\"company\"].str.strip()\n",
    "    filtered_df[\"email pattern\"] = filtered_df[\"email pattern\"].apply(lambda x: x[0] if x else \"NA\")\n",
    "    filtered_df= filtered_df[['company', 'email pattern']]\n",
    "\n",
    "    filtered_df = filtered_df[filtered_df['email pattern'] != 'NA']\n",
    "    print (filtered_df)\n",
    "    filtered_df.to_csv(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          company                            email pattern\n",
      "1           intrig management co.                        FirstName@7-10.in\n",
      "4               intrinsic quality  FirstName.LastName@intrinsicquality.com\n",
      "6    introba usa ross & baruzzini         FirstInitialLastName@rossbar.com\n",
      "7                    introlligent               FirstName@introlligent.com\n",
      "9                         intruno                    FirstName@intruno.com\n",
      "..                            ...                                      ...\n",
      "418                    itc hotels          FirstName.LastName@itchotels.in\n",
      "419                  itc services       FirstName.LastName@itcinfotech.com\n",
      "422                       itechwx         FirstInitialLastName@itechwv.com\n",
      "423       itelbpo smart solutions         FirstName@itel-international.com\n",
      "424               itelligence usa           FirstName.LastName@nttdata.com\n",
      "\n",
      "[186 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# f = [\"/Users/sumanverma/Documents/Work/Email_tool/email_creator_app/files/test_files copy/Batch 0_2590_1991_30_2025-03-15.csv\" ,  \n",
    "#       \"/Users/sumanverma/Documents/Work/Email_tool/email_creator_app/files/test_files copy/Batch 2590_3217_1991_7_2025-03-15.csv\",   \"Batch 5180_7741_1991_30_2025-03-11.csv\"]\n",
    "\n",
    "f = [\"Batch 0_2590_1991_30_2025-03-15.csv\" ,  \n",
    "      \"Batch 2590_3044_1991_5_2025-03-15.csv\"]\n",
    "\n",
    "\n",
    "yesterday_data = pd.read_csv(f[1])\n",
    "get_email_patterns_only(yesterday_data, \"today_local2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4034\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "# Read the pickle file\n",
    "with open(\"/Users/sumanverma/Documents/Work/Email_tool/email_creator_app/files/main_database/email_patterns.pkl\", \"rb\") as file:\n",
    "    data_dict = pickle.load(file)  # Load as a dictionary\n",
    "\n",
    "# Print or use the dictionary\n",
    "print(len(data_dict))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Unnamed: 0', 'unnamed: 0', 'unnamed: 0.1', 'srl no', 'company',\n",
      "       'contact name', 'first name', 'last name', 'designation', 'location',\n",
      "       'industry', 'mailer_status', 'email', 'domain', 'match'],\n",
      "      dtype='object')\n",
      "   unnamed: 0  unnamed: 0  unnamed: 0.1  srl no  \\\n",
      "0           0           0             0  775582   \n",
      "3           3           3             3  784470   \n",
      "4           4           4             4  785181   \n",
      "6           6           6             6  803770   \n",
      "7           7           7             7  803828   \n",
      "\n",
      "                            company      contact name first name  last name  \\\n",
      "0  new mexico children's foundation        Lucy River       lucy      river   \n",
      "3            independence pet group    Melanie Gentry    melanie     gentry   \n",
      "4             hwashin america corp.   Terrell Coleman    terrell    coleman   \n",
      "6                       hydac group  Robert Hauptmann     robert  hauptmann   \n",
      "7                   ipex by aliaxis        Edwin Hart      edwin       hart   \n",
      "\n",
      "                         designation                              location  \\\n",
      "0  program and marketing coordinator   santa fe, new mexico, united states   \n",
      "3    customer service representative                 greater columbus area   \n",
      "4    customer service representative  childersburg, alabama, united states   \n",
      "6                    rga coordinator        niles, illinois, united states   \n",
      "7    customer service representative       denver, colorado, united states   \n",
      "\n",
      "   industry  mailer_status                             email  \\\n",
      "0       NaN            NaN        lucy.river@childrensmn.org   \n",
      "3       NaN            NaN  mgentry@independencepetgroup.com   \n",
      "4       NaN            NaN     terrell.coleman@hwashin.co.kr   \n",
      "6       NaN            NaN        robert.hauptmann@hydac.com   \n",
      "7       NaN            NaN             edwin.hart@ipexna.com   \n",
      "\n",
      "                     domain   match  \n",
      "0           childrensmn.org  Medium  \n",
      "3  independencepetgroup.com    High  \n",
      "4             hwashin.co.kr  Medium  \n",
      "6                 hydac.com  Medium  \n",
      "7                ipexna.com  Medium  \n"
     ]
    }
   ],
   "source": [
    "from get_email_flags import get_flags\n",
    "getflag = r'/Users/sumanverma/Documents/Work/Email_tool/email_creator_app/files/created_emails/combined_email_output.csv'\n",
    "filtered_df = pd.read_csv(getflag)\n",
    "print (filtered_df.columns)\n",
    "# filtered_df = filtered_df[['Srl No', 'Company', 'Contact Name', 'First Name',\n",
    "#        'Last Name', 'Designation', 'Location', 'Industry', 'Mailer_Status',\n",
    "#        'Email']]\n",
    "df = get_flags(filtered_df,'email')\n",
    "\n",
    "df = df[df['match'].isin(['High', 'Medium'])]\n",
    "print (df.head())\n",
    "\n",
    "df.to_csv(getflag,index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(52, 3)\n",
      "   email_formats_list             emailemail_list email_patterns_list\n",
      "22       First.Middle      First.Middle@gmail.com     Unknown Pattern\n",
      "23   First.MiddleLast  First.MiddleLast@gmail.com     Unknown Pattern\n",
      "26   FirstMiddle.Last  FirstMiddle.Last@gmail.com     Unknown Pattern\n",
      "29     Hester.Jenkins    Hester.Jenkins@gmail.com     Unknown Pattern\n",
      "31                JLS               JLS@gmail.com     Unknown Pattern\n",
      "32            JLSmith           JLSmith@gmail.com     Unknown Pattern\n",
      "33        JMichaelDoe       JMichaelDoe@gmail.com     Unknown Pattern\n",
      "35              JSmit             JSmit@gmail.com     Unknown Pattern\n",
      "37            Joh.Doe           Joh.Doe@gmail.com     Unknown Pattern\n",
      "38          Joh.Smith         Joh.Smith@gmail.com     Unknown Pattern\n",
      "41        John.Kucans       John.Kucans@gmail.com     Unknown Pattern\n",
      "42       John.L.Smith      John.L.Smith@gmail.com     Unknown Pattern\n"
     ]
    }
   ],
   "source": [
    "df_filter = df[df[\"email_patterns_list\"]== 'Unknown Pattern']\n",
    "print (df_filter.shape)\n",
    "df_filter.to_csv(\"leftoutfornat.csv\")\n",
    "print (df_filter.head(12))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DJohn@gmail.com: Unknown Pattern\n",
      "FL@gmail.com: Unknown Pattern\n",
      "FiLast@gmail.com: Unknown Pattern\n",
      "Fir.Last@gmail.com: Unknown Pattern\n",
      "First.Middle@gmail.com: Unknown Pattern\n",
      "First.MiddleLast@gmail.com: Unknown Pattern\n",
      "FirstL@gmail.com: Unknown Pattern\n",
      "FirstMiddle.Last@gmail.com: Unknown Pattern\n",
      "Firstname.Lastname@gmail.com: Unknown Pattern\n",
      "Hester.Jenkins@gmail.com: Unknown Pattern\n",
      "JLS@gmail.com: Unknown Pattern\n",
      "JLSmith@gmail.com: Unknown Pattern\n",
      "JMichaelDoe@gmail.com: Unknown Pattern\n",
      "JS@gmail.com: InitialsOnly\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def get_email_pattern(email):\n",
    "    if not isinstance(email, str) or \"@\" not in email:\n",
    "        return \"NA\"\n",
    "\n",
    "    email_prefix = email.split(\"@\")[0].strip().lower()\n",
    "    email_prefix = email_prefix.replace(\" '.' \", \".\").replace(\" '-' \", \"-\").replace(\" '_' \", \"_\")\n",
    "    email_prefix = re.sub(r\"\\s+\", \"\", email_prefix)  # Remove spaces\n",
    "\n",
    "    # Define test names\n",
    "    first_name = \"john\"\n",
    "    middle_name = \"michael\"\n",
    "    last_name = \"smith\"\n",
    "\n",
    "    # Define patterns\n",
    "    patterns = {\n",
    "        \"FirstName\": first_name,\n",
    "        \"LastName\": last_name,\n",
    "        \"FirstName.LastName\": f\"{first_name}.{last_name}\",\n",
    "        \"FirstName_LastName\": f\"{first_name}_{last_name}\",\n",
    "        \"LastName.FirstName\": f\"{last_name}.{first_name}\",\n",
    "        \"LastName_FirstName\": f\"{last_name}_{first_name}\",\n",
    "        \"FirstInitialLast\": f\"{first_name[0]}{last_name}\",\n",
    "        \"FirstInitialMiddleInitialLast\": f\"{first_name[0]}{middle_name[0]}{last_name}\",\n",
    "        \"FirstMiddleLast\": f\"{first_name}{middle_name}{last_name}\",\n",
    "        \"FirstMiddle.Last\": f\"{first_name}{middle_name}.{last_name}\",\n",
    "        \"First.MiddleLast\": f\"{first_name}.{middle_name}{last_name}\",\n",
    "        \"FirstL\": f\"{first_name}{last_name[0]}\",\n",
    "        \"LastName.FirstName\": f\"{last_name}.{first_name}\",\n",
    "        \"FirstName1LastName\": f\"{first_name[0]}{last_name}\",\n",
    "        \"FirstName1.LastName\": f\"{first_name[0]}.{last_name}\",\n",
    "        \"FirstName1_LastName\": f\"{first_name[0]}_{last_name}\",\n",
    "        \"FirstName_LastName1\": f\"{first_name}_{last_name[0]}\",\n",
    "        \"FirstInitialLast\": f\"{first_name[0]}{last_name}\",\n",
    "        \"InitialsOnly\": f\"{first_name[0]}{last_name[0]}\",\n",
    "    }\n",
    "\n",
    "    for pattern_name, pattern in patterns.items():\n",
    "        if pattern == email_prefix:\n",
    "            return pattern_name\n",
    "\n",
    "    return \"Unknown Pattern\"\n",
    "\n",
    "# Test cases\n",
    "emails = [\n",
    "    \"DJohn@gmail.com\", \"FL@gmail.com\", \"FiLast@gmail.com\",\n",
    "    \"Fir.Last@gmail.com\", \"First.Middle@gmail.com\", \"First.MiddleLast@gmail.com\",\n",
    "    \"FirstL@gmail.com\", \"FirstMiddle.Last@gmail.com\", \"Firstname.Lastname@gmail.com\",\n",
    "    \"Hester.Jenkins@gmail.com\", \"JLS@gmail.com\", \"JLSmith@gmail.com\",\n",
    "    \"JMichaelDoe@gmail.com\", \"JS@gmail.com\"\n",
    "]\n",
    "\n",
    "for email in emails:\n",
    "    print(f\"{email}: {get_email_pattern(email)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# Function to extract only the format before @\n",
    "def extract_format(email):\n",
    "    match = re.match(r\"([\\w\\s'.\\-_]+)@\", email)  # Capture everything before '@'\n",
    "    return match.group(1).strip() if match else None\n",
    "\n",
    "# Extract unique combinations\n",
    "unique_formats = set()  # Use set to ensure uniqueness\n",
    "\n",
    "for email_list in filter_df[\"email_formats_list\"]:\n",
    "    for email in email_list:\n",
    "        format_part = extract_format(email)\n",
    "        if format_part:\n",
    "            unique_formats.add(format_part)  # Store only the unique format part\n",
    "\n",
    "# Convert set to sorted list (optional, for readability)\n",
    "unique_formats_list = sorted(unique_formats)\n",
    "\n",
    "# Print unique email format combinations\n",
    "print(unique_formats_list)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
